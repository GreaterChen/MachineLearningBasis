{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-28T16:17:59.663309500Z",
     "start_time": "2023-05-28T16:17:42.676096100Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.image_utils import load_img, img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merging import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "\n",
    "# from keras.initializers import glorot_uniform\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "#from tensorflow.keras.engine import Layer, InputSpec\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.metrics import classification_report, log_loss, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "['adhirasam',\n 'aloo_gobi',\n 'aloo_matar',\n 'aloo_methi',\n 'aloo_shimla_mirch',\n 'aloo_tikki',\n 'anarsa',\n 'ariselu',\n 'bandar_laddu',\n 'basundi',\n 'bhatura',\n 'bhindi_masala',\n 'biryani',\n 'boondi',\n 'butter_chicken',\n 'chak_hao_kheer',\n 'cham_cham',\n 'chana_masala',\n 'chapati',\n 'chhena_kheeri',\n 'chicken_razala',\n 'chicken_tikka',\n 'chicken_tikka_masala',\n 'chikki',\n 'daal_baati_churma',\n 'daal_puri',\n 'dal_makhani',\n 'dal_tadka',\n 'dharwad_pedha',\n 'doodhpak',\n 'double_ka_meetha',\n 'dum_aloo',\n 'gajar_ka_halwa',\n 'gavvalu',\n 'ghevar',\n 'gulab_jamun',\n 'imarti',\n 'jalebi',\n 'kachori',\n 'kadai_paneer',\n 'kadhi_pakoda',\n 'kajjikaya',\n 'kakinada_khaja',\n 'kalakand',\n 'karela_bharta',\n 'kofta',\n 'kuzhi_paniyaram',\n 'lassi',\n 'ledikeni',\n 'litti_chokha',\n 'lyangcha',\n 'maach_jhol',\n 'makki_di_roti_sarson_da_saag',\n 'malapua',\n 'misi_roti',\n 'misti_doi',\n 'modak',\n 'mysore_pak',\n 'naan',\n 'navrattan_korma',\n 'palak_paneer',\n 'paneer_butter_masala',\n 'phirni',\n 'pithe',\n 'poha',\n 'poornalu',\n 'pootharekulu',\n 'qubani_ka_meetha',\n 'rabri',\n 'rasgulla',\n 'ras_malai',\n 'sandesh',\n 'shankarpali',\n 'sheera',\n 'sheer_korma',\n 'shrikhand',\n 'sohan_halwa',\n 'sohan_papdi',\n 'sutar_feni',\n 'unni_appam']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_names = os.listdir(\"../../data\")\n",
    "food_names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-28T16:17:59.774048700Z",
     "start_time": "2023-05-28T16:17:59.670317700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def cv2_letterbox_image(image, expected_size):\n",
    "    ih, iw = image.shape[0:2]\n",
    "    ew, eh = expected_size\n",
    "    scale = min(eh / ih, ew / iw)\n",
    "    nh = int(ih * scale)\n",
    "    nw = int(iw * scale)\n",
    "    image = cv2.resize(image, (nw, nh), interpolation=cv2.INTER_CUBIC)\n",
    "    top = (eh - nh) // 2\n",
    "    bottom = eh - nh - top\n",
    "    left = (ew - nw) // 2\n",
    "    right = ew - nw - left\n",
    "    new_img = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT)\n",
    "    return new_img"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-28T16:17:59.791357Z",
     "start_time": "2023-05-28T16:17:59.703981700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "def get_resized_image(img_shape):\n",
    "    food_names = os.listdir(\"../../data\")\n",
    "    path = '../../data'\n",
    "    class_type = 0\n",
    "    shapes = []\n",
    "    for dish in tqdm(food_names,desc='running',file=sys.stdout):\n",
    "        dish_path = os.path.join(path,dish) + '/'\n",
    "        for count, filename in enumerate(os.listdir(dish_path)):\n",
    "            image_path = os.path.join(dish_path, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            shapes.append(image.shape)\n",
    "            resized_image = cv2_letterbox_image(image,img_shape)\n",
    "            cv2.imwrite(f\"../../data_bak/{dish}/{filename}\",resized_image)\n",
    "# get_resized_image((500,500))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-28T16:17:59.793309200Z",
     "start_time": "2023-05-28T16:17:59.741911700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running: 100%|██████████| 80/80 [00:39<00:00,  2.02it/s]\n"
     ]
    }
   ],
   "source": [
    "def split_train_test(occupation):\n",
    "    path = '../../data_bak'\n",
    "    food_names = os.listdir(path)\n",
    "    X_train=[]\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test =[]\n",
    "    dish_dict = {}\n",
    "    class_type = 0\n",
    "    for dish in tqdm(food_names,desc='running',file=sys.stdout):\n",
    "        dish_dict[dish] = class_type\n",
    "        dish_path = os.path.join(path,dish) + '/'\n",
    "        for count, filename in enumerate(os.listdir(dish_path)):\n",
    "            image_path = os.path.join(dish_path, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            if count < 50*occupation:\n",
    "                X_train.append(image)\n",
    "                y_train.append(class_type)\n",
    "            else:\n",
    "                X_test.append(image)\n",
    "                y_test.append(class_type)\n",
    "        class_type += 1\n",
    "    return X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = split_train_test(0.8)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-28T16:18:39.475385500Z",
     "start_time": "2023-05-28T16:17:59.774048700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def create_pairs(images, labels):\n",
    "    # initialize two empty lists to hold the (image, image) pairs and\n",
    "    # labels to indicate if a pair is positive or negative\n",
    "    random.seed(42)\n",
    "    pairImages = []\n",
    "    pairLabels = []\n",
    "\n",
    "    # calculate the total number of classes present in the dataset\n",
    "    # and then build a list of indexes for each class label that\n",
    "    # provides the indexes for all examples with a given label\n",
    "    numClasses = len(np.unique(y_test))\n",
    "    classes=np.unique(y_test)\n",
    "    idx = [np.where(y_test == classes[i]) for i in range(0, numClasses)]\n",
    "\n",
    "    # loop over all images\n",
    "    for idxA in range(len(images)):\n",
    "        # grab the current image and label belonging to the current iteration\n",
    "        currentImage = images[idxA]\n",
    "        label = labels[idxA]\n",
    "\n",
    "        # randomly pick an image that belongs to the *same* class\n",
    "        # label\n",
    "        #posId = random.choice(list(np.where(labels == label)))\n",
    "        posIdx =random.choice([index for index, element in enumerate(labels) if element == label])\n",
    "        posImage = images[posIdx]\n",
    "\n",
    "        # prepare a positive pair and update the images and labels\n",
    "        pairImages.append([currentImage, posImage])\n",
    "        pairLabels.append([1])\n",
    "\n",
    "        # grab the indices for each of the class labels *not* equal to\n",
    "        # the current label and randomly pick an image corresponding\n",
    "        # to a label *not* equal to the current label\n",
    "        #negId = random.choice(list(np.where(labels != label)))\n",
    "        negIdx =random.choice([index for index, element in enumerate(labels) if element != label])\n",
    "        negImage = images[negIdx]\n",
    "\n",
    "        # prepare a negative pair of images and update our lists\n",
    "        pairImages.append([currentImage, negImage])\n",
    "        pairLabels.append([0])\n",
    "\n",
    "    return (np.array(pairImages), np.array(pairLabels))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-28T16:21:48.946571300Z",
     "start_time": "2023-05-28T16:21:48.937929500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "6400"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pairTrain, labelTrain) = create_pairs(X_train, y_train)\n",
    "(pairTest, labelTest) = create_pairs(X_test, y_test)\n",
    "len(pairTrain)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-28T16:22:26.174567600Z",
     "start_time": "2023-05-28T16:21:49.620691700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairTest[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-28T16:30:22.117704100Z",
     "start_time": "2023-05-28T16:30:22.078346500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 500, 500, 3)]     0         \n",
      "                                                                 \n",
      " vgg19 (Functional)          (None, 15, 15, 512)       20024384  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                32832     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,057,216\n",
      "Trainable params: 2,392,640\n",
      "Non-trainable params: 17,664,576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "IMG_SHAPE = (500,500,3)\n",
    "def tf_siamese_nn(shape, embedding=64, fineTune=False):\n",
    "    inputs = tf.keras.layers.Input(shape)\n",
    "    preprocess_fn = preprocess_input\n",
    "    base_model = tf.keras.applications.vgg19.VGG19(input_shape=shape, include_top=False,                                               weights='imagenet')\n",
    "\n",
    "    if fineTune==False:\n",
    "        base_model.trainable=False\n",
    "    else:\n",
    "        base_model.trainable = True\n",
    "        # Fine-tune from this layer onwards\n",
    "        fine_tune_at = len(base_model.layers)-int(len(base_model.layers)*.10)\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "        for layer in base_model.layers[:fine_tune_at]:\n",
    "          layer.trainable =  False\n",
    "    x=base_model(inputs)\n",
    "    x=tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs=tf.keras.layers.Dense(embedding)(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "model1=tf_siamese_nn(IMG_SHAPE, 64, True)\n",
    "model1.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-28T16:52:49.514006500Z",
     "start_time": "2023-05-28T16:52:46.406604Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def euclidean_distance(vectors):\n",
    "    # unpack the vectors into separate lists\n",
    "    (featsA, featsB) = vectors\n",
    "    # compute the sum of squared distances between the vectors\n",
    "    sumSquared = K.sum(K.square(featsA - featsB), axis=1,keepdims=True)\n",
    "    # return the euclidean distance between the vectors\n",
    "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-28T16:52:53.408538900Z",
     "start_time": "2023-05-28T16:52:53.384380100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "img1 = tf.keras.layers.Input(shape=IMG_SHAPE)\n",
    "img2 =  tf.keras.layers.Input( shape=IMG_SHAPE)\n",
    "featureExtractor = tf_siamese_nn(IMG_SHAPE)\n",
    "featsA = featureExtractor(img1)\n",
    "featsB = featureExtractor(img2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-28T16:52:56.919853300Z",
     "start_time": "2023-05-28T16:52:54.178051500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "distance = tf.keras.layers.Lambda(euclidean_distance)([featsA, featsB])\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "model = tf.keras.Model(inputs=[img1, img2], outputs=outputs)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-28T16:52:59.455214700Z",
     "start_time": "2023-05-28T16:52:59.246635300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.47 GiB for an array with shape (6400, 500, 500, 3) and data type uint8",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mpairTrain\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpairTrain\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabelTrain\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\softwares\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mD:\\softwares\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001B[0m, in \u001B[0;36mconvert_to_eager_tensor\u001B[1;34m(value, ctx, dtype)\u001B[0m\n\u001B[0;32m    100\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mas_dtype(dtype)\u001B[38;5;241m.\u001B[39mas_datatype_enum\n\u001B[0;32m    101\u001B[0m ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m--> 102\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEagerTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 4.47 GiB for an array with shape (6400, 500, 500, 3) and data type uint8"
     ]
    }
   ],
   "source": [
    "history = model.fit([pairTrain[:, 0], pairTrain[:, 1]], labelTrain[:], batch_size=1, epochs=20)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-28T16:53:43.319826Z",
     "start_time": "2023-05-28T16:53:00.381716900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
